{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install librosa==0.10.2.post1 soundfile==0.12.1 \\\n",
        "                 scikit-learn==1.6.0 matplotlib==3.9.0 \\\n",
        "                 lime==0.2.0.1 shap==0.46.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0saXhqApFhjB",
        "outputId": "5a384506-23a6-4495-822e-b3056cf39840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m139.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.9/543.9 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alzheimer’s Detection — Pure RNN with Regularization + Full Explainable AI\n",
        "# Audio (MFCC + Spectrogram + Saliency) + Text (TF-IDF + LIME + SHAP)\n",
        "# Train: 100 Control + 100 Dementia\n",
        "# Test: Remaining samples | Holdout: 4 Control + 4 Dementia unseen\n",
        "# Model: Pure bidirectional RNN with L1 + L2 regularization\n",
        "\n",
        "import os, random, pathlib, warnings, math\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, f1_score, accuracy_score,\n",
        "    roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
        ")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import librosa, librosa.display as lbd\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import shap\n",
        "from google.colab import drive\n",
        "\n",
        "# CONFIGURATION\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "EPOCHS = 6\n",
        "BATCH = 8\n",
        "MAX_DUR = 12.0\n",
        "N_MFCC = 40\n",
        "SAVE_ROOT = pathlib.Path('/content/Alzheimers_RNN_Full_XAI')\n",
        "SAVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "BASE = pathlib.Path('/content/drive/MyDrive/Alzheimers_Organized')\n",
        "CONTROL_DIR, DEMENTIA_DIR = BASE/'control', BASE/'dementia'\n",
        "\n",
        "# DATASET LOADING\n",
        "def list_pairs(root, label):\n",
        "    items = []\n",
        "    for wav in sorted(root.rglob('*.wav')):\n",
        "        txt = wav.with_suffix('.txt')\n",
        "        if txt.exists():\n",
        "            items.append((str(wav), str(txt), label, wav.name))\n",
        "    print(f\"{root.name}: {len(items)} pairs\")\n",
        "    return items\n",
        "\n",
        "ctl, dem = list_pairs(CONTROL_DIR, 0), list_pairs(DEMENTIA_DIR, 1)\n",
        "all_items = ctl + dem\n",
        "print(\"Total pairs:\", len(all_items))\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "def pick(arr, n):\n",
        "    n = min(n, len(arr))\n",
        "    return rng.choice(arr, size=n, replace=False).tolist()\n",
        "\n",
        "idx_ctl = [i for i,(_,_,lab,_) in enumerate(all_items) if lab==0]\n",
        "idx_dem = [i for i,(_,_,lab,_) in enumerate(all_items) if lab==1]\n",
        "\n",
        "train_ctl, train_dem = pick(idx_ctl, 100), pick(idx_dem, 100)\n",
        "train_idx = set(train_ctl + train_dem)\n",
        "rem_ctl = [i for i in idx_ctl if i not in train_idx]\n",
        "rem_dem = [i for i in idx_dem if i not in train_idx]\n",
        "hold_ctl, hold_dem = pick(rem_ctl, 4), pick(rem_dem, 4)\n",
        "hold_idx = set(hold_ctl + hold_dem)\n",
        "test_idx = set(i for i in range(len(all_items)) if i not in train_idx | hold_idx)\n",
        "\n",
        "def gather(idxs):\n",
        "    wavs, txts, labels, fnames = [], [], [], []\n",
        "    for i in idxs:\n",
        "        w,t,l,f = all_items[i]\n",
        "        wavs.append(w); txts.append(t); labels.append(l); fnames.append(f)\n",
        "    return wavs, txts, np.array(labels), fnames\n",
        "\n",
        "tr_wav, tr_txt, tr_y, tr_fn = gather(train_idx)\n",
        "te_wav, te_txt, te_y, te_fn = gather(test_idx)\n",
        "ho_wav, ho_txt, ho_y, ho_fn = gather(hold_idx)\n",
        "print(f\"Train={len(tr_y)} | Test={len(te_y)} | Holdout={len(ho_y)}\")\n",
        "\n",
        "# AUDIO FEATURE EXTRACTION\n",
        "def compute_mfcc(y, sr):\n",
        "    m = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC).T\n",
        "    d = librosa.feature.delta(m.T).T\n",
        "    d2= librosa.feature.delta(d.T).T\n",
        "    f = np.concatenate([m,d,d2], 1)\n",
        "    f = (f - f.mean(0)) / (f.std(0)+1e-8)\n",
        "    return f.astype(np.float32)\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, wavs, labels, max_dur=MAX_DUR):\n",
        "        self.wavs, self.labels, self.max_dur = wavs, torch.LongTensor(labels), max_dur\n",
        "    def __len__(self): return len(self.wavs)\n",
        "    def __getitem__(self, i):\n",
        "        y, sr = librosa.load(self.wavs[i], sr=None, mono=True, duration=self.max_dur)\n",
        "        if len(y)==0: y = np.zeros(int(16000))\n",
        "        return {'audio': torch.tensor(compute_mfcc(y, sr)), 'label': self.labels[i]}\n",
        "\n",
        "def collate_pad(batch):\n",
        "    T = max(b['audio'].shape[0] for b in batch)\n",
        "    D = batch[0]['audio'].shape[1]\n",
        "    aud=[]\n",
        "    for b in batch:\n",
        "        a = b['audio']\n",
        "        if a.shape[0] < T:\n",
        "            pad = torch.zeros(T - a.shape[0], D)\n",
        "            a = torch.cat([a, pad], 0)\n",
        "        aud.append(a)\n",
        "    return {'audio': torch.stack(aud), 'label': torch.stack([b['label'] for b in batch])}\n",
        "\n",
        "train_dl = DataLoader(AudioDataset(tr_wav, tr_y), batch_size=BATCH, shuffle=True, collate_fn=collate_pad)\n",
        "test_dl  = DataLoader(AudioDataset(te_wav, te_y), batch_size=BATCH, shuffle=False, collate_fn=collate_pad)\n",
        "hold_dl  = DataLoader(AudioDataset(ho_wav, ho_y), batch_size=1, shuffle=False, collate_fn=collate_pad)\n",
        "\n",
        "# MODEL: Pure RNN with Regularization\n",
        "class AudioRNN(nn.Module):\n",
        "    def __init__(self, inp=120, hid=256, layers=2, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(inp, hid, layers, batch_first=True, dropout=drop, bidirectional=True)\n",
        "        self.att = nn.Linear(hid*2, 1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hid*2, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(drop),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        h,_ = self.rnn(x)\n",
        "        w = torch.softmax(self.att(h), dim=1)\n",
        "        z = (w*h).sum(1)\n",
        "        return self.fc(z), h, w\n",
        "\n",
        "def l1_penalty(model, λ): return λ*sum(p.abs().sum() for p in model.parameters())\n",
        "def l2_penalty(model, λ): return λ*sum((p**2).sum() for p in model.parameters())\n",
        "\n",
        "model = AudioRNN().to(DEVICE)\n",
        "summary(model, input_size=(300,120))  # model summary\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lambda_l1, lambda_l2 = 1e-5, 1e-4\n",
        "\n",
        "# TRAINING LOOP\n",
        "def train_epoch(m, dl):\n",
        "    m.train(); total=0\n",
        "    for b in dl:\n",
        "        x=b['audio'].to(DEVICE); y=b['label'].to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out,_,_=m(x)\n",
        "        loss = criterion(out,y)+l1_penalty(m,lambda_l1)+l2_penalty(m,lambda_l2)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(m.parameters(),1.0)\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "    return total/len(dl)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(m, dl):\n",
        "    m.eval(); total=0; P=[]; Prob=[]; T=[]\n",
        "    for b in dl:\n",
        "        x=b['audio'].to(DEVICE); y=b['label'].to(DEVICE)\n",
        "        out,_,_=m(x)\n",
        "        loss = criterion(out,y); total += loss.item()\n",
        "        p = torch.softmax(out,1)\n",
        "        P += p.argmax(1).cpu().tolist()\n",
        "        Prob += p[:,1].cpu().tolist()\n",
        "        T += y.cpu().tolist()\n",
        "    return total/len(dl), np.array(P), np.array(Prob), np.array(T)\n",
        "\n",
        "best_f1, best_path = 0, SAVE_ROOT/'best_audio_rnn.pt'\n",
        "for ep in range(EPOCHS):\n",
        "    tr_loss = train_epoch(model, train_dl)\n",
        "    vl_loss, P, Prob, T = eval_epoch(model, test_dl)\n",
        "    f1 = f1_score(T,P,average='weighted')\n",
        "    print(f\"Epoch {ep+1}: Train={tr_loss:.4f} Val={vl_loss:.4f} F1={f1:.4f}\")\n",
        "    if f1>best_f1:\n",
        "        best_f1=f1\n",
        "        torch.save(model.state_dict(),best_path)\n",
        "\n",
        "model.load_state_dict(torch.load(best_path,map_location=DEVICE))\n",
        "\n",
        "# TEST METRICS + CONFUSION MATRIX + ROC CURVE\n",
        "vl_loss, P, Prob, T = eval_epoch(model, test_dl)\n",
        "print(\"\\nCLASSIFICATION REPORT (Audio RNN):\")\n",
        "print(classification_report(T,P,target_names=['Control','Dementia']))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(T,P))\n",
        "print(\"Accuracy:\", accuracy_score(T,P))\n",
        "print(\"F1:\", f1_score(T,P,average='weighted'))\n",
        "print(\"AUC:\", roc_auc_score(T,Prob))\n",
        "\n",
        "# --- Confusion Matrix Plot ---\n",
        "cm = confusion_matrix(T, P)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Control','Dementia'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix (Audio RNN)\")\n",
        "plt.savefig(SAVE_ROOT/'confusion_matrix.png', dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# --- AUC-ROC Curve ---\n",
        "auc = roc_auc_score(T, Prob)\n",
        "fpr, tpr, _ = roc_curve(T, Prob)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"AUC-ROC Curve (Audio RNN)\")\n",
        "plt.legend(); plt.grid(True)\n",
        "plt.tight_layout(); plt.savefig(SAVE_ROOT/'roc_curve.png', dpi=150); plt.close()\n",
        "\n",
        "print(\"Saved ROC and Confusion Matrix plots.\")\n",
        "\n",
        "# AUDIO SALIENCY + SPECTROGRAM\n",
        "def plot_spectrogram(wav, save):\n",
        "    y,sr=librosa.load(wav,sr=None,mono=True,duration=MAX_DUR)\n",
        "    S=librosa.feature.melspectrogram(y=y,sr=sr,n_mels=64)\n",
        "    S_db=librosa.power_to_db(S,ref=np.max)\n",
        "    plt.figure(figsize=(10,3))\n",
        "    lbd.specshow(S_db,sr=sr,x_axis='time',y_axis='mel')\n",
        "    plt.title(\"Mel-Spectrogram\"); plt.tight_layout()\n",
        "    plt.savefig(save,dpi=150); plt.close()\n",
        "\n",
        "def audio_saliency(wav, save):\n",
        "    y,sr=librosa.load(wav,sr=None,mono=True,duration=MAX_DUR)\n",
        "    f=compute_mfcc(y,sr)\n",
        "    x=torch.tensor(f).unsqueeze(0).to(DEVICE).requires_grad_(True)\n",
        "    model.train()\n",
        "    o,_,_=model(x)\n",
        "    cls=o.argmax(1); loss=o[0,cls]; loss.backward(); model.eval()\n",
        "    sal=x.grad.abs().mean(2).cpu().numpy()[0]\n",
        "    sal=(sal-sal.min())/(np.ptp(sal)+1e-8)\n",
        "    S=librosa.feature.melspectrogram(y=y,sr=sr,n_mels=64)\n",
        "    S_db=librosa.power_to_db(S,ref=np.max)\n",
        "    plt.figure(figsize=(10,3))\n",
        "    lbd.specshow(S_db,sr=sr,x_axis='time',y_axis='mel')\n",
        "    plt.plot(np.linspace(0,S_db.shape[1],len(sal)),sal*S_db.shape[0],color='r')\n",
        "    plt.title(\"Audio Saliency over Spectrogram\"); plt.tight_layout()\n",
        "    plt.savefig(save,dpi=150); plt.close()\n",
        "\n",
        "picked=[]; seen=set()\n",
        "for i,y in enumerate(ho_y):\n",
        "    if y not in seen: seen.add(y); picked.append(i)\n",
        "for i in picked:\n",
        "    base = ho_fn[i].replace('.wav','')\n",
        "    plot_spectrogram(ho_wav[i], SAVE_ROOT/f\"spectrogram_{base}.png\")\n",
        "    audio_saliency(ho_wav[i], SAVE_ROOT/f\"saliency_{base}.png\")\n",
        "    print(\"Saved spectrogram and saliency for:\", base)\n",
        "\n",
        "# TEXT MODEL (BoW + LIME + SHAP)\n",
        "tr_texts=[pathlib.Path(t).read_text(errors='ignore') for t in tr_txt]\n",
        "te_texts=[pathlib.Path(t).read_text(errors='ignore') for t in te_txt]\n",
        "ho_texts=[pathlib.Path(t).read_text(errors='ignore') for t in ho_txt]\n",
        "\n",
        "tfidf=TfidfVectorizer(max_features=5000,ngram_range=(1,2),lowercase=True)\n",
        "Xtr=tfidf.fit_transform(tr_texts)\n",
        "bow=LogisticRegression(max_iter=500,class_weight='balanced',solver='liblinear')\n",
        "bow.fit(Xtr,tr_y)\n",
        "Xte=tfidf.transform(te_texts)\n",
        "bow_pred=bow.predict(Xte)\n",
        "bow_prob=bow.predict_proba(Xte)[:,1]\n",
        "print(\"\\nCLASSIFICATION REPORT (Text BoW):\")\n",
        "print(classification_report(te_y,bow_pred,target_names=['Control','Dementia']))\n",
        "print(\"Confusion Matrix:\\n\",confusion_matrix(te_y,bow_pred))\n",
        "print(\"Accuracy:\",accuracy_score(te_y,bow_pred))\n",
        "print(\"AUC:\",roc_auc_score(te_y,bow_prob))\n",
        "\n",
        "# LIME\n",
        "if len(ho_texts)>0:\n",
        "    explainer=LimeTextExplainer(class_names=['Control','Dementia'])\n",
        "    exp=explainer.explain_instance(ho_texts[0],lambda x:bow.predict_proba(tfidf.transform(x)),num_features=10)\n",
        "    lime_path=SAVE_ROOT/'lime_explanation.html'\n",
        "    exp.save_to_file(str(lime_path))\n",
        "    print(\"LIME saved:\",lime_path)\n",
        "\n",
        "# SHAP\n",
        "print(\"\\nRunning SHAP...\")\n",
        "X_train_tfidf=tfidf.transform(tr_texts)\n",
        "expl=shap.LinearExplainer(bow,X_train_tfidf)\n",
        "X_hold=tfidf.transform(ho_texts[:3])\n",
        "vals=expl.shap_values(X_hold)\n",
        "shap.summary_plot(vals,X_hold,feature_names=tfidf.get_feature_names_out(),show=False)\n",
        "plt.savefig(SAVE_ROOT/'shap_summary.png',dpi=150); plt.close()\n",
        "print(\"SHAP summary saved.\")\n",
        "\n",
        "print(\"\\nArtifacts saved in:\", SAVE_ROOT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im_maskqhqcz",
        "outputId": "f2cc6c48-67ef-40c6-dbdc-b2667bfe54b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "control: 237 pairs\n",
            "dementia: 131 pairs\n",
            "Total pairs: 368\n",
            "Train=200 | Test=160 | Holdout=8\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "               RNN-1  [[-1, 300, 512], [-1, 2, 256]]               0\n",
            "            Linear-2               [-1, 300, 1]             513\n",
            "            Linear-3                  [-1, 128]          65,664\n",
            "              ReLU-4                  [-1, 128]               0\n",
            "           Dropout-5                  [-1, 128]               0\n",
            "            Linear-6                    [-1, 2]             258\n",
            "================================================================\n",
            "Total params: 66,435\n",
            "Trainable params: 66,435\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.14\n",
            "Forward/backward pass size (MB): 599.99\n",
            "Params size (MB): 0.25\n",
            "Estimated Total Size (MB): 600.39\n",
            "----------------------------------------------------------------\n",
            "Epoch 1: Train=0.9681 Val=0.7470 F1=0.0487\n",
            "Epoch 2: Train=0.9411 Val=0.6908 F1=0.7132\n",
            "Epoch 3: Train=0.9057 Val=0.4765 F1=0.7547\n",
            "Epoch 4: Train=0.9152 Val=0.6282 F1=0.7547\n",
            "Epoch 5: Train=0.8929 Val=0.6583 F1=0.7547\n",
            "Epoch 6: Train=0.8857 Val=0.7317 F1=0.0487\n",
            "\n",
            "CLASSIFICATION REPORT (Audio RNN):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Control       0.83      1.00      0.91       133\n",
            "    Dementia       0.00      0.00      0.00        27\n",
            "\n",
            "    accuracy                           0.83       160\n",
            "   macro avg       0.42      0.50      0.45       160\n",
            "weighted avg       0.69      0.83      0.75       160\n",
            "\n",
            "Confusion Matrix:\n",
            " [[133   0]\n",
            " [ 27   0]]\n",
            "Accuracy: 0.83125\n",
            "F1: 0.7546501706484642\n",
            "AUC: 0.44277360066833754\n",
            "Saved ROC and Confusion Matrix plots.\n",
            "Saved spectrogram and saliency for: CaseyKasem_5\n",
            "Saved spectrogram and saliency for: WilliamShatner_3\n",
            "\n",
            "CLASSIFICATION REPORT (Text BoW):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Control       0.87      0.62      0.72       133\n",
            "    Dementia       0.23      0.56      0.32        27\n",
            "\n",
            "    accuracy                           0.61       160\n",
            "   macro avg       0.55      0.59      0.52       160\n",
            "weighted avg       0.76      0.61      0.65       160\n",
            "\n",
            "Confusion Matrix:\n",
            " [[82 51]\n",
            " [12 15]]\n",
            "Accuracy: 0.60625\n",
            "AUC: 0.6663881927039822\n",
            "LIME saved: /content/Alzheimers_RNN_Full_XAI/lime_explanation.html\n",
            "\n",
            "Running SHAP...\n",
            "SHAP summary saved.\n",
            "\n",
            "Artifacts saved in: /content/Alzheimers_RNN_Full_XAI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without Regularization"
      ],
      "metadata": {
        "id": "IeU7Q068t1bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alzheimer’s Detection — Pure RNN (No Regularization) + Explainable AI\n",
        "# Includes: Audio MFCC + Spectrogram + Saliency + Text BoW + LIME + SHAP\n",
        "\n",
        "import os, random, pathlib, warnings, math\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, roc_auc_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import librosa, librosa.display as lbd\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import shap\n",
        "from google.colab import drive\n",
        "\n",
        "# CONFIGURATION\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "EPOCHS = 6\n",
        "BATCH = 8\n",
        "MAX_DUR = 12.0\n",
        "N_MFCC = 40\n",
        "SAVE_ROOT = pathlib.Path('/content/Alzheimers_RNN_XAI_Spectrogram')\n",
        "SAVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "BASE = pathlib.Path('/content/drive/MyDrive/Alzheimers_Organized')\n",
        "CONTROL_DIR, DEMENTIA_DIR = BASE/'control', BASE/'dementia'\n",
        "\n",
        "# DATASET LOADING\n",
        "def list_pairs(root, label):\n",
        "    items = []\n",
        "    for wav in sorted(root.rglob('*.wav')):\n",
        "        txt = wav.with_suffix('.txt')\n",
        "        if txt.exists():\n",
        "            items.append((str(wav), str(txt), label, wav.name))\n",
        "    print(f\"{root.name}: {len(items)} pairs\")\n",
        "    return items\n",
        "\n",
        "ctl, dem = list_pairs(CONTROL_DIR, 0), list_pairs(DEMENTIA_DIR, 1)\n",
        "all_items = ctl + dem\n",
        "print(\"Total pairs:\", len(all_items))\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "def pick(arr, n):\n",
        "    n = min(n, len(arr))\n",
        "    return rng.choice(arr, size=n, replace=False).tolist()\n",
        "\n",
        "idx_ctl = [i for i,(_,_,lab,_) in enumerate(all_items) if lab==0]\n",
        "idx_dem = [i for i,(_,_,lab,_) in enumerate(all_items) if lab==1]\n",
        "\n",
        "train_ctl, train_dem = pick(idx_ctl, 100), pick(idx_dem, 100)\n",
        "train_idx = set(train_ctl + train_dem)\n",
        "\n",
        "rem_ctl = [i for i in idx_ctl if i not in train_idx]\n",
        "rem_dem = [i for i in idx_dem if i not in train_idx]\n",
        "hold_ctl, hold_dem = pick(rem_ctl, 4), pick(rem_dem, 4)\n",
        "hold_idx = set(hold_ctl + hold_dem)\n",
        "\n",
        "test_idx = set(i for i in range(len(all_items)) if i not in train_idx | hold_idx)\n",
        "\n",
        "def gather(idxs):\n",
        "    wavs, txts, labels, fnames = [], [], [], []\n",
        "    for i in idxs:\n",
        "        w,t,l,f = all_items[i]\n",
        "        wavs.append(w); txts.append(t); labels.append(l); fnames.append(f)\n",
        "    return wavs, txts, np.array(labels), fnames\n",
        "\n",
        "tr_wav, tr_txt, tr_y, tr_fn = gather(train_idx)\n",
        "te_wav, te_txt, te_y, te_fn = gather(test_idx)\n",
        "ho_wav, ho_txt, ho_y, ho_fn = gather(hold_idx)\n",
        "\n",
        "print(f\"Train={len(tr_y)} | Test={len(te_y)} | Holdout={len(ho_y)}\")\n",
        "\n",
        "# AUDIO FEATURE EXTRACTION\n",
        "def compute_mfcc(y, sr):\n",
        "    m = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC).T\n",
        "    d = librosa.feature.delta(m.T).T\n",
        "    d2= librosa.feature.delta(d.T).T\n",
        "    f = np.concatenate([m,d,d2], 1)\n",
        "    f = (f - f.mean(0)) / (f.std(0)+1e-8)\n",
        "    return f.astype(np.float32)\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, wavs, labels, max_dur=MAX_DUR):\n",
        "        self.wavs, self.labels, self.max_dur = wavs, torch.LongTensor(labels), max_dur\n",
        "    def __len__(self): return len(self.wavs)\n",
        "    def __getitem__(self, i):\n",
        "        y, sr = librosa.load(self.wavs[i], sr=None, mono=True, duration=self.max_dur)\n",
        "        if len(y)==0:\n",
        "            y = np.zeros(int(16000))\n",
        "        return {'audio': torch.tensor(compute_mfcc(y, sr)), 'label': self.labels[i]}\n",
        "\n",
        "def collate_pad(batch):\n",
        "    T = max(b['audio'].shape[0] for b in batch)\n",
        "    D = batch[0]['audio'].shape[1]\n",
        "    aud=[]\n",
        "    for b in batch:\n",
        "        a = b['audio']\n",
        "        if a.shape[0] < T:\n",
        "            pad = torch.zeros(T - a.shape[0], D)\n",
        "            a = torch.cat([a, pad], 0)\n",
        "        aud.append(a)\n",
        "    return {'audio': torch.stack(aud), 'label': torch.stack([b['label'] for b in batch])}\n",
        "\n",
        "train_dl = DataLoader(AudioDataset(tr_wav, tr_y), batch_size=BATCH, shuffle=True, collate_fn=collate_pad)\n",
        "test_dl  = DataLoader(AudioDataset(te_wav, te_y), batch_size=BATCH, shuffle=False, collate_fn=collate_pad)\n",
        "hold_dl  = DataLoader(AudioDataset(ho_wav, ho_y), batch_size=1, shuffle=False, collate_fn=collate_pad)\n",
        "\n",
        "# MODEL: Pure RNN (No Regularization)\n",
        "class AudioRNN(nn.Module):\n",
        "    def __init__(self, inp=120, hid=256, layers=2, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(inp, hid, layers, batch_first=True, dropout=drop, bidirectional=True)\n",
        "        self.att = nn.Linear(hid*2, 1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hid*2, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(drop),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        h,_ = self.rnn(x)\n",
        "        w = torch.softmax(self.att(h), dim=1)\n",
        "        z = (w*h).sum(1)\n",
        "        return self.fc(z), h, w\n",
        "\n",
        "model = AudioRNN().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# TRAINING\n",
        "def train_epoch(m, dl):\n",
        "    m.train(); total=0\n",
        "    for b in dl:\n",
        "        x=b['audio'].to(DEVICE); y=b['label'].to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out,_,_=m(x)\n",
        "        loss = criterion(out,y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(m.parameters(),1.0)\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "    return total/len(dl)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(m, dl):\n",
        "    m.eval(); total=0; P=[]; Prob=[]; T=[]\n",
        "    for b in dl:\n",
        "        x=b['audio'].to(DEVICE); y=b['label'].to(DEVICE)\n",
        "        out,_,_=m(x)\n",
        "        loss = criterion(out,y); total += loss.item()\n",
        "        p = torch.softmax(out,1)\n",
        "        P += p.argmax(1).cpu().tolist()\n",
        "        Prob += p[:,1].cpu().tolist()\n",
        "        T += y.cpu().tolist()\n",
        "    return total/len(dl), np.array(P), np.array(Prob), np.array(T)\n",
        "\n",
        "best_f1, best_path = 0, SAVE_ROOT/'best_audio_rnn.pt'\n",
        "for ep in range(EPOCHS):\n",
        "    tr_loss = train_epoch(model, train_dl)\n",
        "    vl_loss, P, Prob, T = eval_epoch(model, test_dl)\n",
        "    f1 = f1_score(T,P,average='weighted')\n",
        "    print(f\"Epoch {ep+1}: Train={tr_loss:.4f} Val={vl_loss:.4f} F1={f1:.4f}\")\n",
        "    if f1>best_f1:\n",
        "        best_f1=f1\n",
        "        torch.save(model.state_dict(),best_path)\n",
        "\n",
        "model.load_state_dict(torch.load(best_path,map_location=DEVICE))\n",
        "\n",
        "# EVALUATION\n",
        "vl_loss, P, Prob, T = eval_epoch(model, test_dl)\n",
        "print(\"\\nCLASSIFICATION REPORT (Audio RNN):\")\n",
        "print(classification_report(T,P,target_names=['Control','Dementia']))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(T,P))\n",
        "print(\"Accuracy:\", accuracy_score(T,P))\n",
        "print(\"F1:\", f1_score(T,P,average='weighted'))\n",
        "print(\"AUC:\", roc_auc_score(T,Prob))\n",
        "\n",
        "# HOLDOUT PREDICTIONS\n",
        "print(\"\\nHOLDOUT PREDICTIONS:\")\n",
        "labels={0:'Control',1:'Dementia'}\n",
        "@torch.no_grad()\n",
        "def predict_one(x):\n",
        "    out,_,_=model(x.to(DEVICE))\n",
        "    return torch.softmax(out,1)[0].cpu().numpy()\n",
        "\n",
        "for i,b in enumerate(hold_dl):\n",
        "    p=predict_one(b['audio'])\n",
        "    gt=b['label'][0].item()\n",
        "    print(f\"{i+1:02d}. {ho_fn[i]} | GT={labels[gt]} | Pred={labels[int(p[1]>0.5)]} ({p[1]:.3f})\")\n",
        "\n",
        "# EXPLAINABILITY: SPECTROGRAM + SALIENCY\n",
        "def plot_spectrogram(wav, save):\n",
        "    y,sr=librosa.load(wav,sr=None,mono=True,duration=MAX_DUR)\n",
        "    S=librosa.feature.melspectrogram(y=y,sr=sr,n_mels=64)\n",
        "    S_db=librosa.power_to_db(S,ref=np.max)\n",
        "    plt.figure(figsize=(10,3))\n",
        "    lbd.specshow(S_db,sr=sr,x_axis='time',y_axis='mel')\n",
        "    plt.title(\"Mel-Spectrogram\")\n",
        "    plt.tight_layout(); plt.savefig(save,dpi=150); plt.close()\n",
        "\n",
        "def audio_saliency(wav, save):\n",
        "    y,sr=librosa.load(wav,sr=None,mono=True,duration=MAX_DUR)\n",
        "    f=compute_mfcc(y,sr)\n",
        "    x=torch.tensor(f).unsqueeze(0).to(DEVICE).requires_grad_(True)\n",
        "    model.train()\n",
        "    o,_,_=model(x)\n",
        "    cls=o.argmax(1)\n",
        "    loss=o[0,cls]; loss.backward()\n",
        "    model.eval()\n",
        "    sal=x.grad.abs().mean(2).cpu().numpy()[0]\n",
        "    sal=(sal-sal.min())/(np.ptp(sal)+1e-8)\n",
        "    S=librosa.feature.melspectrogram(y=y,sr=sr,n_mels=64)\n",
        "    S_db=librosa.power_to_db(S,ref=np.max)\n",
        "    plt.figure(figsize=(10,3))\n",
        "    lbd.specshow(S_db,sr=sr,x_axis='time',y_axis='mel')\n",
        "    plt.plot(np.linspace(0,S_db.shape[1],len(sal)),sal*S_db.shape[0],color='r')\n",
        "    plt.title(\"Audio Saliency over Spectrogram\")\n",
        "    plt.tight_layout(); plt.savefig(save,dpi=150); plt.close()\n",
        "\n",
        "picked=[]\n",
        "seen=set()\n",
        "for i,y in enumerate(ho_y):\n",
        "    if y not in seen: seen.add(y); picked.append(i)\n",
        "for i in picked:\n",
        "    base = ho_fn[i].replace('.wav','')\n",
        "    plot_spectrogram(ho_wav[i], SAVE_ROOT/f\"spectrogram_{base}.png\")\n",
        "    audio_saliency(ho_wav[i], SAVE_ROOT/f\"saliency_{base}.png\")\n",
        "    print(\"Saved spectrogram and saliency for:\", base)\n",
        "\n",
        "# TEXT MODEL (BoW + LIME + SHAP)\n",
        "tr_texts=[pathlib.Path(t).read_text(errors='ignore') for t in tr_txt]\n",
        "te_texts=[pathlib.Path(t).read_text(errors='ignore') for t in te_txt]\n",
        "ho_texts=[pathlib.Path(t).read_text(errors='ignore') for t in ho_txt]\n",
        "\n",
        "tfidf=TfidfVectorizer(max_features=5000,ngram_range=(1,2),lowercase=True)\n",
        "Xtr=tfidf.fit_transform(tr_texts)\n",
        "bow=LogisticRegression(max_iter=500,class_weight='balanced',solver='liblinear')\n",
        "bow.fit(Xtr,tr_y)\n",
        "Xte=tfidf.transform(te_texts)\n",
        "bow_pred=bow.predict(Xte)\n",
        "bow_prob=bow.predict_proba(Xte)[:,1]\n",
        "print(\"\\nCLASSIFICATION REPORT (Text BoW):\")\n",
        "print(classification_report(te_y,bow_pred,target_names=['Control','Dementia']))\n",
        "print(\"Confusion Matrix:\\n\",confusion_matrix(te_y,bow_pred))\n",
        "print(\"Accuracy:\",accuracy_score(te_y,bow_pred))\n",
        "print(\"AUC:\",roc_auc_score(te_y,bow_prob))\n",
        "\n",
        "# LIME\n",
        "if len(ho_texts)>0:\n",
        "    explainer=LimeTextExplainer(class_names=['Control','Dementia'])\n",
        "    exp=explainer.explain_instance(ho_texts[0],lambda x:bow.predict_proba(tfidf.transform(x)),num_features=10)\n",
        "    lime_path=SAVE_ROOT/'lime_explanation.html'\n",
        "    exp.save_to_file(str(lime_path))\n",
        "    print(\"LIME saved:\",lime_path)\n",
        "\n",
        "# SHAP\n",
        "print(\"\\nRunning SHAP...\")\n",
        "X_train_tfidf=tfidf.transform(tr_texts)\n",
        "expl=shap.LinearExplainer(bow,X_train_tfidf)\n",
        "X_hold=tfidf.transform(ho_texts[:3])\n",
        "vals=expl.shap_values(X_hold)\n",
        "shap.summary_plot(vals,X_hold,feature_names=tfidf.get_feature_names_out(),show=False)\n",
        "plt.savefig(SAVE_ROOT/'shap_summary.png',dpi=150); plt.close()\n",
        "print(\"SHAP summary saved.\")\n",
        "\n",
        "print(\"\\nArtifacts saved in:\", SAVE_ROOT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpstOchqXZLO",
        "outputId": "c9858644-631f-496c-81e2-9e8790377bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "control: 237 pairs\n",
            "dementia: 131 pairs\n",
            "Total pairs: 368\n",
            "Train=200 | Test=160 | Holdout=8\n",
            "Epoch 1: Train=0.7001 Val=0.6958 F1=0.4186\n",
            "Epoch 2: Train=0.6988 Val=0.7143 F1=0.0487\n",
            "Epoch 3: Train=0.7001 Val=0.6880 F1=0.7547\n",
            "Epoch 4: Train=0.7031 Val=0.6704 F1=0.7547\n",
            "Epoch 5: Train=0.7046 Val=0.6311 F1=0.7547\n",
            "Epoch 6: Train=0.7048 Val=0.7227 F1=0.0487\n",
            "\n",
            "CLASSIFICATION REPORT (Audio RNN):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Control       0.83      1.00      0.91       133\n",
            "    Dementia       0.00      0.00      0.00        27\n",
            "\n",
            "    accuracy                           0.83       160\n",
            "   macro avg       0.42      0.50      0.45       160\n",
            "weighted avg       0.69      0.83      0.75       160\n",
            "\n",
            "Confusion Matrix:\n",
            " [[133   0]\n",
            " [ 27   0]]\n",
            "Accuracy: 0.83125\n",
            "F1: 0.7546501706484642\n",
            "AUC: 0.4909495962127541\n",
            "\n",
            "HOLDOUT PREDICTIONS:\n",
            "01. CaseyKasem_5.wav | GT=Dementia | Pred=Control (0.497)\n",
            "02. TimConway_5.wav | GT=Dementia | Pred=Control (0.496)\n",
            "03. WilliamShatner_3.wav | GT=Control | Pred=Control (0.497)\n",
            "04. Jessejackson_0.wav | GT=Dementia | Pred=Control (0.495)\n",
            "05. Morgen Freeman_2.wav | GT=Control | Pred=Control (0.496)\n",
            "06. JimmyFratianno_0.wav | GT=Dementia | Pred=Control (0.496)\n",
            "07. Clint Eastwood_2.wav | GT=Control | Pred=Control (0.496)\n",
            "08. DavidCronenberg_1.wav | GT=Control | Pred=Control (0.496)\n",
            "Saved spectrogram and saliency for: CaseyKasem_5\n",
            "Saved spectrogram and saliency for: WilliamShatner_3\n",
            "\n",
            "CLASSIFICATION REPORT (Text BoW):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Control       0.87      0.62      0.72       133\n",
            "    Dementia       0.23      0.56      0.32        27\n",
            "\n",
            "    accuracy                           0.61       160\n",
            "   macro avg       0.55      0.59      0.52       160\n",
            "weighted avg       0.76      0.61      0.65       160\n",
            "\n",
            "Confusion Matrix:\n",
            " [[82 51]\n",
            " [12 15]]\n",
            "Accuracy: 0.60625\n",
            "AUC: 0.6663881927039822\n",
            "LIME saved: /content/Alzheimers_RNN_XAI_Spectrogram/lime_explanation.html\n",
            "\n",
            "Running SHAP...\n",
            "SHAP summary saved.\n",
            "\n",
            "Artifacts saved in: /content/Alzheimers_RNN_XAI_Spectrogram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AUC-ROC Curve Plot#\n",
        "\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make sure T (true labels) and Prob (predicted dementia probabilities) exist\n",
        "# If not, recompute them using:\n",
        "# _, P, Prob, T = eval_epoch(model, test_dl)\n",
        "\n",
        "auc = roc_auc_score(T, Prob)\n",
        "fpr, tpr, _ = roc_curve(T, Prob)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"AUC-ROC Curve (Audio RNN)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(SAVE_ROOT / \"roc_curve.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"AUC-ROC curve saved to: {SAVE_ROOT / 'roc_curve.png'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "OqeZ4xRmdTSb",
        "outputId": "f77bd555-ba67-4dbc-e82b-fee61b28703e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-ROC curve saved to: /content/Alzheimers_RNN_XAI_Spectrogram/roc_curve.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full robust multimodal (audio + text) pipeline with PyTorch RNN classifier\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Mount Drive (works even if already mounted)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "except Exception as e:\n",
        "    # If not running in Colab, ignore\n",
        "    pass\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# Config / Paths\n",
        "BASE = pathlib.Path('/content/drive/MyDrive/Alzheimers_Organized')\n",
        "CONTROL_DIR = BASE / 'control'\n",
        "DEMENTIA_DIR = BASE / 'dementia'\n",
        "SAVE_ROOT = pathlib.Path('/content/drive/MyDrive/Alzheimers_Multimodal_Model')\n",
        "SAVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Control exists:\", CONTROL_DIR.exists(), \"  Dementia exists:\", DEMENTIA_DIR.exists())\n",
        "\n",
        "# Helper: read transcript robustly\n",
        "def read_transcript_for_wav(wav_path):\n",
        "    \"\"\"\n",
        "    Try to find a transcript file matching wav basename.\n",
        "    If not found or empty, return placeholder \"speech_unavailable\".\n",
        "    \"\"\"\n",
        "    base = pathlib.Path(wav_path).with_suffix('')\n",
        "    # Preferred transcript extensions (in order)\n",
        "    exts = ['.txt', '.srt', '.vtt', '.csv', '.json']\n",
        "    for ext in exts:\n",
        "        p = base.with_suffix(ext)\n",
        "        if p.exists():\n",
        "            try:\n",
        "                with open(p, 'r', errors='ignore') as f:\n",
        "                    txt = f.read().strip()\n",
        "                if len(txt) >= 3:\n",
        "                    return txt\n",
        "            except Exception:\n",
        "                continue\n",
        "    # If not found by exact basename, try to find any text file in same folder\n",
        "    folder = base.parent\n",
        "    for candidate in folder.iterdir():\n",
        "        if candidate.suffix.lower() in {'.txt', '.srt', '.vtt', '.csv', '.json'}:\n",
        "            try:\n",
        "                with open(candidate, 'r', errors='ignore') as f:\n",
        "                    txt = f.read().strip()\n",
        "                if len(txt) >= 3:\n",
        "                    return txt\n",
        "            except Exception:\n",
        "                continue\n",
        "    # Fall back\n",
        "    return \"speech_unavailable\"\n",
        "\n",
        "# Collect dataset: wav + transcript + labels\n",
        "pairs = []  # tuples (wav_path, transcript_text, label, filename)\n",
        "for dirpath, label in [(CONTROL_DIR, 0), (DEMENTIA_DIR, 1)]:\n",
        "    if not dirpath.exists():\n",
        "        print(f\"Warning: {dirpath} does not exist\")\n",
        "        continue\n",
        "    # iterate recursively (in case files are in subfolders)\n",
        "    for wav in sorted(dirpath.rglob(\"*.wav\")):\n",
        "        wav = pathlib.Path(wav)\n",
        "        transcript = read_transcript_for_wav(wav)\n",
        "        pairs.append((str(wav), transcript, label, wav.name))\n",
        "\n",
        "print(f\"Total audio-transcript pairs found: {len(pairs)}\")\n",
        "if len(pairs) == 0:\n",
        "    raise SystemExit(\"No audio files found. Check your BASE path and folder structure.\")\n",
        "\n",
        "# AUDIO FEATURE: MFCC + delta + delta2 mean\n",
        "N_MFCC = 40\n",
        "MAX_DUR = None  # set if you want to limit duration (seconds); None -> full file\n",
        "\n",
        "def compute_mfcc_features(wav_path, n_mfcc=N_MFCC, max_dur=MAX_DUR):\n",
        "    y, sr = librosa.load(wav_path, sr=None, mono=True, duration=max_dur)\n",
        "    if y is None or y.size == 0:\n",
        "        # fallback to zeros\n",
        "        y = np.zeros(16000)\n",
        "        sr = 16000\n",
        "    # MFCC: shape (n_mfcc, frames)\n",
        "    m = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    # delta, delta2\n",
        "    d = librosa.feature.delta(m)\n",
        "    d2 = librosa.feature.delta(m, order=2)\n",
        "    # concatenate along feature axis\n",
        "    feat = np.concatenate([m, d, d2], axis=0)  # shape (n_mfcc*3, frames)\n",
        "    # reduce variable time length by mean pooling (per feature)\n",
        "    feat_mean = np.mean(feat, axis=1)  # shape (n_mfcc*3,)\n",
        "    return feat_mean.astype(np.float32)\n",
        "\n",
        "# TEXT FEATURE: TF-IDF with safe fallbacks\n",
        "texts = [t for (_, t, _, _) in pairs]\n",
        "# Pre-check: ensure at least some non-placeholder texts exist\n",
        "usable_texts = [t for t in texts if t and t != \"speech_unavailable\" and len(t.strip())>2]\n",
        "\n",
        "# Choose vectorizer robustly\n",
        "vectorizer = None\n",
        "if len(usable_texts) >= 2:\n",
        "    # try TfidfVectorizer first; be tolerant\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer(max_features=500, stop_words=None, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "        vectorizer.fit(texts)\n",
        "        if len(vectorizer.get_feature_names_out()) == 0:\n",
        "            raise ValueError(\"empty vocab\")\n",
        "        print(\"Using TfidfVectorizer; vocab size:\", len(vectorizer.get_feature_names_out()))\n",
        "    except Exception as e:\n",
        "        print(\"Tfidf failed:\", str(e), \"-- falling back to CountVectorizer\")\n",
        "        try:\n",
        "            vectorizer = CountVectorizer(max_features=500, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "            vectorizer.fit(texts)\n",
        "            print(\"Using CountVectorizer; vocab size:\", len(vectorizer.get_feature_names_out()))\n",
        "        except Exception as e2:\n",
        "            print(\"CountVectorizer failed:\", str(e2), \"-- falling back to HashingVectorizer (stateless)\")\n",
        "            vectorizer = HashingVectorizer(n_features=500)\n",
        "else:\n",
        "    print(\"Not enough usable transcripts for TF-IDF (<=1). Using HashingVectorizer\")\n",
        "    vectorizer = HashingVectorizer(n_features=500)\n",
        "\n",
        "# function to extract text features (works for TFIDF/Count/Hashing)\n",
        "def extract_text_vector(text):\n",
        "    try:\n",
        "        v = vectorizer.transform([text])\n",
        "        # if vectorizer is HashingVectorizer, transform returns sparse already; convert dense\n",
        "        if hasattr(v, \"toarray\"):\n",
        "            return v.toarray()[0].astype(np.float32)\n",
        "        else:\n",
        "            return np.array(v, dtype=np.float32)\n",
        "    except Exception:\n",
        "        # fallback to placeholder vector\n",
        "        return np.zeros(getattr(vectorizer, \"n_features\", 500), dtype=np.float32)\n",
        "\n",
        "# Build fused features array\n",
        "audio_feats = []\n",
        "text_feats = []\n",
        "labels = []\n",
        "filenames = []\n",
        "\n",
        "print(\"Extracting features ...\")\n",
        "for wav_path, txt, lab, fname in tqdm(pairs):\n",
        "    a = compute_mfcc_features(wav_path)\n",
        "    t = extract_text_vector(txt)\n",
        "    # ensure dims\n",
        "    if a.ndim != 1:\n",
        "        a = a.flatten()\n",
        "    if t.ndim != 1:\n",
        "        t = t.flatten()\n",
        "    fused = np.concatenate([a, t]).astype(np.float32)\n",
        "    audio_feats.append(a)\n",
        "    text_feats.append(t)\n",
        "    labels.append(int(lab))\n",
        "    filenames.append(fname)\n",
        "\n",
        "X = np.stack([np.concatenate([a, t]) for a, t in zip(audio_feats, text_feats)], axis=0)\n",
        "y = np.array(labels, dtype=np.int64)\n",
        "\n",
        "print(\"Fused feature shape:\", X.shape, \"Labels shape:\", y.shape)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Save vectorizer + scaler for later use\n",
        "joblib.dump(vectorizer, SAVE_ROOT / \"text_vectorizer.joblib\")\n",
        "joblib.dump(scaler, SAVE_ROOT / \"feature_scaler.joblib\")\n",
        "print(\"Saved vectorizer and scaler to\", SAVE_ROOT)\n",
        "\n",
        "# Train/test split (stratified)\n",
        "if len(np.unique(y)) == 1:\n",
        "    raise SystemExit(\"Dataset has only one label class — cannot train classifier. Check your data folders.\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train/test sizes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# PyTorch Dataset & DataLoader\n",
        "# We'll reshape features as (seq_len=1, feat_dim) for RNN input\n",
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # RNN expects (batch, seq_len, feat_dim)\n",
        "        return self.X[idx].unsqueeze(0), self.y[idx]\n",
        "\n",
        "batch_size = 16\n",
        "train_ds = FusionDataset(X_train, y_train)\n",
        "test_ds = FusionDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
        "\n",
        "# RNN classifier (binary)\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, bidirectional=False, dropout=0.2):\n",
        "        super().__init__()\n",
        "        # use Simple RNN; you can switch to nn.LSTM if desired\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, nonlinearity='tanh', dropout=0, bidirectional=bidirectional)\n",
        "        out_dim = hidden_dim * (2 if bidirectional else 1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(out_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1)  # binary\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, feat_dim)\n",
        "        out, h_n = self.rnn(x)  # out: (batch, seq_len, hidden*dirs)\n",
        "        # take last timestep\n",
        "        last = out[:, -1, :]\n",
        "        logits = self.fc(last).squeeze(1)\n",
        "        return logits\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = RNNClassifier(input_dim=input_dim, hidden_dim=128, num_layers=1, bidirectional=True, dropout=0.3)\n",
        "model = model.to(DEVICE)\n",
        "print(model)\n",
        "\n",
        "# Training setup\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "EPOCHS = 5\n",
        "\n",
        "# Training loop\n",
        "best_val_f1 = 0.0\n",
        "best_state = None\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for Xb, yb in train_loader:\n",
        "        Xb = Xb.to(DEVICE)  # shape (B, 1, feat_dim)\n",
        "        yb = yb.to(DEVICE).float()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(Xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * Xb.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(train_ds)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    probs = []\n",
        "    trues = []\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in test_loader:\n",
        "            Xb = Xb.to(DEVICE)\n",
        "            logits = model(Xb)\n",
        "            prob = torch.sigmoid(logits).cpu().numpy()\n",
        "            pred = (prob > 0.5).astype(int)\n",
        "            preds.extend(pred.tolist())\n",
        "            probs.extend(prob.tolist())\n",
        "            trues.extend(yb.numpy().tolist())\n",
        "\n",
        "    try:\n",
        "        val_acc = accuracy_score(trues, preds)\n",
        "        val_f1 = f1_score(trues, preds, average='weighted')\n",
        "    except Exception:\n",
        "        val_acc = 0.0\n",
        "        val_f1 = 0.0\n",
        "\n",
        "    print(f\"Epoch {ep}/{EPOCHS}  TrainLoss={avg_loss:.4f}  ValAcc={val_acc:.4f}  ValF1={val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        best_state = {\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"optimizer_state\": optimizer.state_dict(),\n",
        "            \"epoch\": ep,\n",
        "            \"val_f1\": val_f1\n",
        "        }\n",
        "        torch.save(best_state, SAVE_ROOT / \"best_rnn_multimodal.pt\")\n",
        "\n",
        "# Load best & final evaluation\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state[\"model_state\"])\n",
        "    print(\"Loaded best model from epoch\", best_state[\"epoch\"], \"val_f1=\", best_state[\"val_f1\"])\n",
        "\n",
        "model.eval()\n",
        "preds = []\n",
        "probs = []\n",
        "trues = []\n",
        "filenames_test = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for Xb, yb in test_loader:\n",
        "        Xb = Xb.to(DEVICE)\n",
        "        logits = model(Xb)\n",
        "        prob = torch.sigmoid(logits).cpu().numpy()\n",
        "        pred = (prob > 0.5).astype(int)\n",
        "        probs.extend(prob.tolist())\n",
        "        preds.extend(pred.tolist())\n",
        "        trues.extend(yb.numpy().tolist())\n",
        "\n",
        "print(\"\\nClassification Report (test):\")\n",
        "print(classification_report(trues, preds, digits=4))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(trues, preds))\n",
        "print(\"Accuracy:\", accuracy_score(trues, preds))\n",
        "print(\"F1 weighted:\", f1_score(trues, preds, average='weighted'))\n",
        "# ROC AUC (if both classes present)\n",
        "if len(np.unique(trues)) == 2:\n",
        "    try:\n",
        "        auc = roc_auc_score(trues, np.array(probs)[:, 0] if np.array(probs).ndim>1 else np.array(probs))\n",
        "        print(\"ROC AUC:\", auc)\n",
        "    except Exception as e:\n",
        "        print(\"ROC AUC could not be computed:\", str(e))\n",
        "\n",
        "# Save final artifacts\n",
        "torch.save(model.state_dict(), SAVE_ROOT / \"rnn_multimodal_final_state.pt\")\n",
        "joblib.dump(vectorizer, SAVE_ROOT / \"text_vectorizer.joblib\")\n",
        "joblib.dump(scaler, SAVE_ROOT / \"feature_scaler.joblib\")\n",
        "print(\"Saved final model and artifacts to\", SAVE_ROOT)\n"
      ],
      "metadata": {
        "id": "4B8gu7IFjSgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3389b5d-4407-4bcb-8bf3-a6d09000591b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "Control exists: True   Dementia exists: True\n",
            "Total audio-transcript pairs found: 368\n",
            "Using TfidfVectorizer; vocab size: 500\n",
            "Extracting features ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 368/368 [06:03<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fused feature shape: (368, 620) Labels shape: (368,)\n",
            "Saved vectorizer and scaler to /content/drive/MyDrive/Alzheimers_Multimodal_Model\n",
            "Train/test sizes: (294, 620) (74, 620)\n",
            "RNNClassifier(\n",
            "  (rnn): RNN(620, 128, batch_first=True, bidirectional=True)\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 1/5  TrainLoss=0.6954  ValAcc=0.5811  ValF1=0.5791\n",
            "Epoch 2/5  TrainLoss=0.4999  ValAcc=0.6081  ValF1=0.6063\n",
            "Epoch 3/5  TrainLoss=0.3199  ValAcc=0.6081  ValF1=0.6125\n",
            "Epoch 4/5  TrainLoss=0.1659  ValAcc=0.6351  ValF1=0.6424\n",
            "Epoch 5/5  TrainLoss=0.0698  ValAcc=0.6216  ValF1=0.6296\n",
            "Loaded best model from epoch 4 val_f1= 0.6424310427357466\n",
            "\n",
            "Classification Report (test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7500    0.6250    0.6818        48\n",
            "           1     0.4706    0.6154    0.5333        26\n",
            "\n",
            "    accuracy                         0.6216        74\n",
            "   macro avg     0.6103    0.6202    0.6076        74\n",
            "weighted avg     0.6518    0.6216    0.6296        74\n",
            "\n",
            "Confusion Matrix:\n",
            " [[30 18]\n",
            " [10 16]]\n",
            "Accuracy: 0.6216216216216216\n",
            "F1 weighted: 0.6296478296478296\n",
            "ROC AUC: 0.6386217948717948\n",
            "Saved final model and artifacts to /content/drive/MyDrive/Alzheimers_Multimodal_Model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-5pPLbtLLA_r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}